{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055624ec-88a1-4db7-9eae-41368acaca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:     3.12.7\n",
      "pymc version:       5.23.0\n",
      "numpy version:      1.26.4\n",
      "pandas version:     2.2.2\n",
      "arviz version:      0.21.0\n",
      "matplotlib version: 3.9.2\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries and print their versions\n",
    "%run imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00594862-512d-4b77-951c-195af83c0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model_B02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae37e9d-8aea-4306-9aae-e77f95cc972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_odds_ratio(idata, var_name=\"effect\"):\n",
    "    \"\"\"\n",
    "    Calculates the odds ratio and its 95% HDI from the posterior samples.\n",
    "\n",
    "    Args:\n",
    "        idata (az.InferenceData): InferenceData object.\n",
    "        var_name (str, optional): Name of the parameter. Defaults to \"effect\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with mean, lower, and upper HDI for the odds ratio.\n",
    "                      Returns an empty DataFrame if there's an error.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        posterior_samples = idata.posterior[var_name].values.flatten()\n",
    "        odds_ratios = np.exp(posterior_samples)\n",
    "        hdi = az.hdi(odds_ratios, hdi_prob=0.95)\n",
    "        mean_or = np.mean(odds_ratios)\n",
    "\n",
    "        or_summary = pd.DataFrame({\n",
    "            \"mean\": [mean_or],\n",
    "            \"hdi_lower\": [hdi[0]],\n",
    "            \"hdi_upper\": [hdi[1]]\n",
    "        })\n",
    "        return or_summary\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Variable '{var_name}' not found in posterior.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame to signal error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74eb1d-a811-4444-94f1-1ac3207efb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "def run_and_summarize(data, model_func, label=\"b02\", output_dir=\"../results\", **model_kwargs):\n",
    "    \"\"\"\n",
    "    Runs the specified PyMC model function with data and optional model parameters,\n",
    "    summarizes results, and saves output files including plots, summaries, and metrics.\n",
    "\n",
    "    Parameters:\n",
    "        data (dict): Dictionary with keys 'predictor' and 'outcome'.\n",
    "        model_func (function): PyMC model function to use.\n",
    "        label (str): Label to tag output files.\n",
    "        output_dir (str): Directory to save outputs.\n",
    "        **model_kwargs: Additional keyword arguments passed to model_func.\n",
    "\n",
    "    Returns:\n",
    "        idata (InferenceData): ArviZ inference data object.\n",
    "        waic (ELPDData): WAIC estimate.\n",
    "        loo (ELPDData): LOO estimate.\n",
    "        bic (float): Bayesian Information Criterion.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    #Call the model function with additional model parameters\n",
    "    model, idata, waic, loo, bic = model_func(\n",
    "        data[\"predictor\"],\n",
    "        data[\"outcome\"],\n",
    "        **model_kwargs  # Pass arguments like variant=\"B01\", seed=123, etc.\n",
    "    )\n",
    "\n",
    "    # Save InferenceData\n",
    "    idata_path = os.path.join(output_dir, f\"idata_{label}.nc\")\n",
    "    idata.to_netcdf(idata_path)\n",
    "\n",
    "    # Determine var_names based on model\n",
    "    var_names = [\"intercept\", \"level_effects\"]\n",
    "    if \"effect\" in idata.posterior:\n",
    "        var_names += [\"effect\", \"sd_fluctuation\"]\n",
    "    if \"p\" in idata.posterior:\n",
    "        var_names.append(\"p\")\n",
    "\n",
    "    # Remove problematic or degenerate variables\n",
    "    clean_var_names = []\n",
    "    for var in var_names:\n",
    "        if var in idata.posterior:\n",
    "            values = idata.posterior[var].values\n",
    "            if np.isnan(values).all():\n",
    "                print(f\"‚ö†Ô∏è Skipping '{var}': all NaNs in posterior.\")\n",
    "            elif np.allclose(values, values.mean()):\n",
    "                print(f\"‚ö†Ô∏è Skipping '{var}': constant values in posterior.\")\n",
    "            else:\n",
    "                clean_var_names.append(var)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping '{var}': not found in posterior.\")\n",
    "\n",
    "    # Save Summary\n",
    "    summary = az.summary(idata, var_names=clean_var_names)\n",
    "    summary_path = os.path.join(output_dir, f\"survey_summary_{label}.csv\")\n",
    "    summary.to_csv(summary_path)\n",
    "\n",
    "    # Calculate and save Odds Ratio summary (only for B02)\n",
    "    if \"effect\" in idata.posterior:\n",
    "        try:\n",
    "            or_summary = calculate_odds_ratio(idata)\n",
    "            if not or_summary.empty:\n",
    "                or_summary_path = os.path.join(output_dir, f\"survey_or_summary_{label}.csv\")\n",
    "                or_summary.to_csv(or_summary_path)\n",
    "            else:\n",
    "                print(\"Odds ratio calculation failed. Not saving.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error calculating odds ratio: {e}\")\n",
    "    else:\n",
    "        print(\"Model does not have 'effect' parameter. Skipping OR calculation.\")\n",
    "\n",
    "    # Save WAIC, LOO, BIC as a markdown file\n",
    "    metrics_path = os.path.join(output_dir, f\"survey_model_metrics_{label}.md\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        f.write(f\"## Model {label.upper()} Metrics\\n\\n\")\n",
    "        f.write(\"### WAIC\\n```\\n\" + waic.to_string() + \"\\n```\\n\")\n",
    "        f.write(\"### LOO\\n```\\n\" + loo.to_string() + \"\\n```\\n\")\n",
    "        f.write(f\"### BIC\\n```\\n\\nBIC = {bic:.2f}\\n```\")\n",
    "\n",
    "    # Trace plot (excluding 'p')\n",
    "    trace_vars = [v for v in clean_var_names if v != \"p\"]\n",
    "    if trace_vars:\n",
    "        trace_plot_path = os.path.join(output_dir, f\"survey_trace_{label}.png\")\n",
    "        az.plot_trace(idata, var_names=trace_vars)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(trace_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # Posterior plot for effect (if exists)\n",
    "    if \"effect\" in idata.posterior:\n",
    "        effect_plot_path = os.path.join(output_dir, f\"survey_posterior_effect_{label}.png\")\n",
    "        az.plot_posterior(idata, var_names=[\"effect\"])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(effect_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # Posterior plot for a subset of 'p'\n",
    "    if \"p\" in idata.posterior:\n",
    "        try:\n",
    "            obs_count = idata.posterior[\"p\"].shape[-1]\n",
    "            plot_indices = np.random.choice(obs_count, size=min(20, obs_count), replace=False)\n",
    "            posterior_plot_path = os.path.join(output_dir, f\"survey_posterior_p_{label}.png\")\n",
    "            az.plot_posterior(idata, var_names=[\"p\"], coords={\"obs\": plot_indices})\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(posterior_plot_path, dpi=300)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to plot 'p': {e}\")\n",
    "\n",
    "    # Posterior predictive check\n",
    "    try:\n",
    "        ppc_plot_path = os.path.join(output_dir, f\"survey_ppc_{label}.png\")\n",
    "        az.plot_ppc(idata)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(ppc_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to plot PPC: {e}\")\n",
    "\n",
    "    # Rank plot for diagnostics\n",
    "    try:\n",
    "        rank_plot_path = os.path.join(output_dir, f\"survey_rank_{label}.png\")\n",
    "        az.plot_rank(idata, var_names=trace_vars)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(rank_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to create rank plot: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Saved all outputs for model {label.upper()} in '{output_dir}' folder.\")\n",
    "    return idata, waic, loo, bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfd481-88a3-42b3-a400-593a55529f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_model_diagnostics(idata, model_name=\"Model\", output_dir=\"../results\"):\n",
    "    \"\"\"\n",
    "    Performs standard Bayesian diagnostics on a PyMC InferenceData object.\n",
    "    Saves plots and prints summary messages for convergence, divergences, etc.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\nüîç Running diagnostics for {model_name}...\\n\")\n",
    "\n",
    "    # --- R-hat and ESS ---\n",
    "    summary = az.summary(idata)\n",
    "    rhat_issues = summary[\"r_hat\"].dropna() > 1.05\n",
    "    ess_bulk_issues = summary[\"ess_bulk\"].dropna() < 200\n",
    "    ess_tail_issues = summary[\"ess_tail\"].dropna() < 1000\n",
    "\n",
    "    print(\"üìè R-hat summary:\")\n",
    "    print(summary[\"r_hat\"].dropna())\n",
    "    if rhat_issues.any():\n",
    "        print(f\"‚ö†Ô∏è R-hat > 1.05 for: {list(summary[rhat_issues].index)}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All R-hat values < 1.05\")\n",
    "\n",
    "    print(\"\\nüìè ESS (bulk) summary:\")\n",
    "    print(summary[\"ess_bulk\"].dropna())\n",
    "    if ess_bulk_issues.any():\n",
    "        print(f\"‚ö†Ô∏è ESS < 200 for: {list(summary[ess_bulk_issues].index)}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All ESS values > 200\")\n",
    "\n",
    "    print(\"\\nüìè ESS (tail) summary:\")\n",
    "    print(summary[\"ess_tail\"].dropna())\n",
    "    if ess_tail_issues.any():\n",
    "        print(f\"‚ö†Ô∏è ESS < 1000 for: {list(summary[ess_tail_issues].index)}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All ESS values > 1000\")\n",
    "\n",
    "    # --- Divergences ---\n",
    "    if \"diverging\" in idata.sample_stats:\n",
    "        n_divergences = idata.sample_stats[\"diverging\"].sum().values\n",
    "        print(f\"\\nüö® Divergences: {n_divergences}\")\n",
    "        if n_divergences > 0:\n",
    "            print(\"‚ö†Ô∏è Consider increasing `target_accept` or reparameterizing.\")\n",
    "        else:\n",
    "            print(\"‚úÖ No divergences.\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Divergence info not available.\")\n",
    "\n",
    "    # --- Tree Depth ---\n",
    "    if \"depth\" in idata.sample_stats:\n",
    "        max_depth = idata.sample_stats[\"depth\"].max().values\n",
    "        print(f\"\\nüå≤ Max tree depth reached: {max_depth}\")\n",
    "        if max_depth >= 10:\n",
    "            print(\"‚ö†Ô∏è Consider increasing `max_treedepth` if sampling is inefficient.\")\n",
    "        else:\n",
    "            print(\"‚úÖ Tree depth is within acceptable range.\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Tree depth info not available.\")\n",
    "\n",
    "    # --- Energy plot (E-BFMI) ---\n",
    "    energy_plot_path = os.path.join(output_dir, f\"{model_name.lower()}_energy_plot.png\")\n",
    "    az.plot_energy(idata)\n",
    "    plt.title(\"Energy Transition Plot (E-BFMI)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(energy_plot_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"\\nüìà Saved energy transition plot to: {energy_plot_path}\")\n",
    "\n",
    "    # --- Optional: Posterior Predictive Check Plot ---\n",
    "    if hasattr(idata, \"posterior_predictive\") and \"y_pred\" in idata.posterior_predictive:\n",
    "        ppc_plot_path = os.path.join(output_dir, f\"{model_name.lower()}_ppc_check.png\")\n",
    "        az.plot_ppc(idata)\n",
    "        plt.title(\"Posterior Predictive Check\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(ppc_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"üìà Saved PPC plot to: {ppc_plot_path}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Diagnostic check complete for {model_name}.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9390301-1cff-44d1-b02d-7cd60c35f71e",
   "metadata": {},
   "source": [
    "### Testing the model using the survey dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428a73c7-c6ef-483f-89c3-c31e3ec4d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-26/77-78 27-28/79-80 29-30/81-82 31-32/83-84 33-34/85-86 35-36/87-88 37-38/89-90 39-40/91-92 41-42/93-94 43-44/95-96\n"
     ]
    }
   ],
   "source": [
    "# Survey Data Generation\n",
    "%run code_snippets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69875e5f-41d7-4b25-9276-473dcee1615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id≈ë', 'Befejez√©s', 'Forr√°s',\n",
       "       'V√°ltoztatott-e √∂nsz√°nt√°b√≥l munkahelyet 2022. janu√°r 1. √≥ta?',\n",
       "       'Rendezze sorrendbe fontoss√°g szerint az al√°bbi, a munk√°hoz kapcsol√≥d√≥ √©rt√©keket. A sorba rendez√©shez haszn√°ljon cs√∫szk√°t, ne a nyilakat!\\nMit tartott els≈ësorban, m√°sodsorban stb. fontosnak, amikor munkahelyet v√°ltoztatott? x Kev√©s stresszel j√°r√≥ munka',\n",
       "       'Rendezze sorrendbe fontoss√°g szerint az al√°bbi, a munk√°hoz kapcsol√≥d√≥ √©rt√©keket. A sorba rendez√©shez haszn√°ljon cs√∫szk√°t, ne a nyilakat!\\nMit tartott els≈ësorban, m√°sodsorban stb. fontosnak, amikor munkahelyet v√°ltoztatott? x Hossz√∫ szabads√°g',\n",
       "       'Rendezze sorrendbe fontoss√°g szerint az al√°bbi, a munk√°hoz kapcsol√≥d√≥ √©rt√©keket. A sorba rendez√©shez haszn√°ljon cs√∫szk√°t, ne a nyilakat!\\nMit tartott els≈ësorban, m√°sodsorban stb. fontosnak, amikor munkahelyet v√°ltoztatott? x Szakmai fejl≈ëd√©si lehet≈ës√©g',\n",
       "       'Rendezze sorrendbe fontoss√°g szerint az al√°bbi, a munk√°hoz kapcsol√≥d√≥ √©rt√©keket. A sorba rendez√©shez haszn√°ljon cs√∫szk√°t, ne a nyilakat!\\nMit tartott els≈ësorban, m√°sodsorban stb. fontosnak, amikor munkahelyet v√°ltoztatott? x Felemelked√©si lehet≈ës√©g a hierarchi√°ban',\n",
       "       'Rendezze sorrendbe fontoss√°g szerint az al√°bbi, a munk√°hoz kapcsol√≥d√≥ √©rt√©keket. A sorba rendez√©shez haszn√°ljon cs√∫szk√°t, ne a nyilakat!\\nMit tartott els≈ësorban, m√°sodsorban stb. fontosnak, amikor munkahelyet v√°ltoztatott? x Biztos munkahely (nem kell att√≥l tartanom, hogy munkan√©lk√ºliv√© v√°lok)',\n",
       "       ...\n",
       "       'Mi az oka annak, hogy b√°r sz√°nd√©k√°ban √°ll, m√©gsem val√≥sz√≠n≈±, hogy √∂nsz√°nt√°b√≥l  munkahelyet v√°ltoztat?\\n(Ha nem √°ll fenn ez az ellentmond√°s, legyen a v√°lasza: \"t√°rgytalan\"!).1',\n",
       "       'Az √ñnt foglalkoztat√≥ szervezet m√©rete:',\n",
       "       'Melyik szektorhoz tartozik a szervezete?', 'Mikor sz√ºletett?.1',\n",
       "       'Az √ñn neme:.1', 'A legmagasabb iskolai v√©gzetts√©ge:.1',\n",
       "       'Az √ñn beoszt√°sa:.1',\n",
       "       'Mi az √ñn Neptun-k√≥dja (vagy aki felk√©rte √ñnt a kit√∂lt√©sre):',\n",
       "       'Melyik egyetemen hallgat√≥ √ñn (vagy aki felk√©rte √ñnt a kit√∂lt√©sre):',\n",
       "       'I_I'],\n",
       "      dtype='object', length=112)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347e352c-c0a6-49f0-91ac-7e04dcdc0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to C999 format\n",
    "new_columns = {old_col: f'C{i:03d}' for i, old_col in enumerate(d.columns)}\n",
    "d = d.rename(columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3488d6-8926-4e2e-838c-cf668409a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe with merged \"I_I\" columns (first 5 rows of relevant columns):\n",
      "              C027             C079              I_I\n",
      "0              NaN       Egyet√©rtek       Egyet√©rtek\n",
      "1              NaN       Egyet√©rtek       Egyet√©rtek\n",
      "2  Nem √©rtek egyet              NaN  Nem √©rtek egyet\n",
      "3              NaN  Nem √©rtek egyet  Nem √©rtek egyet\n",
      "4              NaN  Nem √©rtek egyet  Nem √©rtek egyet\n"
     ]
    }
   ],
   "source": [
    "#Merge the predictor columns\n",
    "d[\"I_I\"] = merge_columns(d[\"C027\"], d[\"C079\"])\n",
    "print(\"\\nDataframe with merged \\\"I_I\\\" columns (first 5 rows of relevant columns):\")\n",
    "print(d[[\"C027\", \"C079\", \"I_I\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd9cc84-3c33-45db-bb75-9fcb406256aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in the outcome columns (C004):\n",
      "['Nem' 'Igen']\n"
     ]
    }
   ],
   "source": [
    "#Prepare the outcome variable\n",
    "print(\"\\nUnique values in the outcome columns (C004):\")\n",
    "print(d[\"C004\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d479fa30-8541-466c-b4af-5eed25dd07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with binary outcome:\n",
      "   C004  outcome_binary\n",
      "0   Nem               0\n",
      "1   Nem               0\n",
      "2  Igen               1\n",
      "3   Nem               0\n",
      "4   Nem               0\n"
     ]
    }
   ],
   "source": [
    "d[\"outcome_binary\"] = d[\"C004\"].apply(lambda x: 1 if x == \"Igen\" else 0)\n",
    "print(\"\\nFirst few rows with binary outcome:\")\n",
    "print(d[[\"C004\", \"outcome_binary\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b8cfa1-c8a4-4fb7-9641-5a342d41ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in the merged 'I_I' column:\n",
      "['Egyet√©rtek' 'Nem √©rtek egyet' 'Teljesen egyet√©rtek'\n",
      " 'Egy√°ltal√°n nem √©rtek egyet']\n"
     ]
    }
   ],
   "source": [
    "#Prepare the predictor variable (I_I)\n",
    "print(\"\\nUnique values in the merged 'I_I' column:\")\n",
    "print(d[\"I_I\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb828da-99a4-44d0-819f-330375f77d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in the 'I_I' column after mapping:\n",
      "['I Agree' 'I Do Not Agree' 'I totally Agree' 'I Completely Disagree']\n"
     ]
    }
   ],
   "source": [
    "#Change values of the likert scale to english\n",
    "mapping = {'Egyet√©rtek': 'I Agree', 'Egy√°ltal√°n nem √©rtek egyet': 'I Completely Disagree', 'Nem √©rtek egyet': 'I Do Not Agree', 'Teljesen egyet√©rtek': 'I totally Agree'}\n",
    "d[\"I_I\"] = d[\"I_I\"].map(mapping)\n",
    "print(\"\\nUnique values in the 'I_I' column after mapping:\")\n",
    "print(d[\"I_I\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3394b01d-b67c-4536-83be-8d362d4f7049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C005</th>\n",
       "      <th>C006</th>\n",
       "      <th>C007</th>\n",
       "      <th>C008</th>\n",
       "      <th>C009</th>\n",
       "      <th>C010</th>\n",
       "      <th>C011</th>\n",
       "      <th>C012</th>\n",
       "      <th>C013</th>\n",
       "      <th>C014</th>\n",
       "      <th>...</th>\n",
       "      <th>C068</th>\n",
       "      <th>C069</th>\n",
       "      <th>C070</th>\n",
       "      <th>C071</th>\n",
       "      <th>C072</th>\n",
       "      <th>C073</th>\n",
       "      <th>C074</th>\n",
       "      <th>C075</th>\n",
       "      <th>C076</th>\n",
       "      <th>outcome_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.00000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.648000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>16.688000</td>\n",
       "      <td>12.88800</td>\n",
       "      <td>13.352000</td>\n",
       "      <td>14.024000</td>\n",
       "      <td>16.904000</td>\n",
       "      <td>10.472000</td>\n",
       "      <td>12.976000</td>\n",
       "      <td>11.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.817308</td>\n",
       "      <td>7.456731</td>\n",
       "      <td>9.658654</td>\n",
       "      <td>8.533654</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>4.687500</td>\n",
       "      <td>8.879808</td>\n",
       "      <td>8.721154</td>\n",
       "      <td>6.408654</td>\n",
       "      <td>0.375375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.882913</td>\n",
       "      <td>5.840625</td>\n",
       "      <td>3.798166</td>\n",
       "      <td>4.94847</td>\n",
       "      <td>4.924029</td>\n",
       "      <td>3.766285</td>\n",
       "      <td>2.613316</td>\n",
       "      <td>4.363662</td>\n",
       "      <td>3.670862</td>\n",
       "      <td>4.135605</td>\n",
       "      <td>...</td>\n",
       "      <td>4.417279</td>\n",
       "      <td>4.014232</td>\n",
       "      <td>4.655662</td>\n",
       "      <td>4.684110</td>\n",
       "      <td>4.111225</td>\n",
       "      <td>3.955481</td>\n",
       "      <td>5.625166</td>\n",
       "      <td>5.349535</td>\n",
       "      <td>6.019399</td>\n",
       "      <td>0.484948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             C005        C006        C007       C008        C009        C010  \\\n",
       "count  125.000000  125.000000  125.000000  125.00000  125.000000  125.000000   \n",
       "mean    14.648000   10.200000   16.688000   12.88800   13.352000   14.024000   \n",
       "std      4.882913    5.840625    3.798166    4.94847    4.924029    3.766285   \n",
       "min      2.000000    1.000000    4.000000    1.00000    1.000000    3.000000   \n",
       "25%     11.000000    5.000000   15.000000   10.00000   11.000000   12.000000   \n",
       "50%     16.000000   10.000000   18.000000   14.00000   14.000000   15.000000   \n",
       "75%     19.000000   15.000000   20.000000   17.00000   17.000000   17.000000   \n",
       "max     20.000000   20.000000   20.000000   20.00000   20.000000   20.000000   \n",
       "\n",
       "             C011        C012        C013        C014  ...        C068  \\\n",
       "count  125.000000  125.000000  125.000000  125.000000  ...  208.000000   \n",
       "mean    16.904000   10.472000   12.976000   11.760000  ...    7.817308   \n",
       "std      2.613316    4.363662    3.670862    4.135605  ...    4.417279   \n",
       "min      9.000000    1.000000    4.000000    1.000000  ...    1.000000   \n",
       "25%     15.000000    7.000000   10.000000    9.000000  ...    4.000000   \n",
       "50%     17.000000   11.000000   13.000000   11.000000  ...    8.000000   \n",
       "75%     19.000000   13.000000   16.000000   14.000000  ...   11.000000   \n",
       "max     20.000000   19.000000   20.000000   20.000000  ...   19.000000   \n",
       "\n",
       "             C069        C070        C071        C072        C073        C074  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     7.456731    9.658654    8.533654    5.875000    4.687500    8.879808   \n",
       "std      4.014232    4.655662    4.684110    4.111225    3.955481    5.625166   \n",
       "min      1.000000    2.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      5.000000    6.000000    5.000000    3.000000    2.000000    3.000000   \n",
       "50%      7.000000    9.000000    7.000000    5.000000    4.000000    9.000000   \n",
       "75%     10.000000   13.250000   12.000000    8.000000    7.000000   14.000000   \n",
       "max     19.000000   20.000000   19.000000   17.000000   20.000000   20.000000   \n",
       "\n",
       "             C075        C076  outcome_binary  \n",
       "count  208.000000  208.000000      333.000000  \n",
       "mean     8.721154    6.408654        0.375375  \n",
       "std      5.349535    6.019399        0.484948  \n",
       "min      1.000000    1.000000        0.000000  \n",
       "25%      4.000000    1.000000        0.000000  \n",
       "50%      9.000000    4.000000        0.000000  \n",
       "75%     13.000000   11.000000        1.000000  \n",
       "max     20.000000   20.000000        1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99460fce-1bcb-47ee-b4cf-8235e12213fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Columns: 114 entries, C000 to outcome_binary\n",
      "dtypes: float64(40), int64(1), object(73)\n",
      "memory usage: 296.7+ KB\n"
     ]
    }
   ],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bfcd767-b99b-4dbf-84ff-3a82a9cbd161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C000               0\n",
       "C001               0\n",
       "C002               0\n",
       "C003               0\n",
       "C004               0\n",
       "                  ..\n",
       "C109              24\n",
       "C110              25\n",
       "C111               0\n",
       "I_I                0\n",
       "outcome_binary     0\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bffb2a9-c6ce-4790-9224-9d88ec51b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likert_mapping = {\n",
    "    \"I Completely Disagree\": 1,\n",
    "    \"I Do Not Agree\": 2,\n",
    "    \"I Agree\": 3,\n",
    "    \"I totally Agree\": 4\n",
    "}\n",
    "d[\"I_I_numeric\"] = d[\"I_I\"].map(likert_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd11eae3-ed9e-4636-a4d5-127c2ed5a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for the Bayesian model\n",
    "y = d[\"outcome_binary\"].values\n",
    "X = d[\"I_I_numeric\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298b9f02-4684-4802-8a49-12dbf17773fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictor  outcome\n",
       "0          3        0\n",
       "1          3        0\n",
       "2          2        1\n",
       "3          2        0\n",
       "4          2        0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = pd.DataFrame({\n",
    "        \"predictor\": X,\n",
    "        \"outcome\": y\n",
    "    })\n",
    "d_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65b2ead3-1dc2-4370-b2ed-41e653385b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for B02 Model on survey data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">NUTS: [effect, sd_fluctuation, intercept, level_effects_diff]\n",
      ">BinaryGibbsMetropolis: [y_pred]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03464b3d9df44062b8bd0dd7baf69ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 10_000 tune and 10_000 draw iterations (40_000 + 40_000 draws total) took 2203 seconds.\n",
      "There were 843 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Sampling: [y_obs]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c460abf07e4cbc9105c3de444167d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barakat Ogunjoun\\AppData\\Local\\Temp\\ipykernel_26136\\1115879529.py:119: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Barakat Ogunjoun\\AppData\\Local\\Temp\\ipykernel_26136\\1115879529.py:120: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(ppc_plot_path, dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved all outputs for model B02 in 'results' folder.\n",
      "\n",
      "üîç Running diagnostics for B02...\n",
      "\n",
      "üìè R-hat summary:\n",
      "effect                   1.0\n",
      "intercept                1.0\n",
      "level_effects_diff[0]    1.0\n",
      "level_effects_diff[1]    1.0\n",
      "level_effects_diff[2]    1.0\n",
      "                        ... \n",
      "p[328]                   1.0\n",
      "p[329]                   1.0\n",
      "p[330]                   1.0\n",
      "p[331]                   1.0\n",
      "p[332]                   1.0\n",
      "Name: r_hat, Length: 676, dtype: float64\n",
      "‚úÖ All R-hat values < 1.05\n",
      "\n",
      "üìè ESS (bulk) summary:\n",
      "effect                   1022.0\n",
      "intercept                4199.0\n",
      "level_effects_diff[0]    4585.0\n",
      "level_effects_diff[1]    9059.0\n",
      "level_effects_diff[2]    3496.0\n",
      "                          ...  \n",
      "p[328]                   9974.0\n",
      "p[329]                   3771.0\n",
      "p[330]                   9974.0\n",
      "p[331]                   9974.0\n",
      "p[332]                   9974.0\n",
      "Name: ess_bulk, Length: 676, dtype: float64\n",
      "‚úÖ All ESS values > 200\n",
      "\n",
      "üìè ESS (tail) summary:\n",
      "effect                    1239.0\n",
      "intercept                 8174.0\n",
      "level_effects_diff[0]     9676.0\n",
      "level_effects_diff[1]    13156.0\n",
      "level_effects_diff[2]     9330.0\n",
      "                          ...   \n",
      "p[328]                   18413.0\n",
      "p[329]                   10426.0\n",
      "p[330]                   18413.0\n",
      "p[331]                   18413.0\n",
      "p[332]                   18413.0\n",
      "Name: ess_tail, Length: 676, dtype: float64\n",
      "‚úÖ All ESS values > 1000\n",
      "\n",
      "üö® Divergences: 843\n",
      "‚ö†Ô∏è Consider increasing `target_accept` or reparameterizing.\n",
      "‚ÑπÔ∏è Tree depth info not available.\n",
      "\n",
      "üìà Saved energy transition plot to: results\\b02_energy_plot.png\n",
      "\n",
      "‚úÖ Diagnostic check complete for B02.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run and save results for B02 for survey data\n",
    "print(\"\\nResults for B02 Model on survey data:\")\n",
    "idata, *_ = run_and_summarize(d_model, ordinal_predictor_binary_outcome_model, label = \"b02\", shape = 3)\n",
    "run_model_diagnostics(idata, model_name=\"B02\", output_dir=\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857feea0-a3c2-438f-8793-aaa8415c0bfc",
   "metadata": {},
   "source": [
    "## Getting Group Size Ratio PastEx to PresentEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8cd0862-5ba2-4147-ac10-48fa6f46c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of PastEx to PresentEx: 0.6009615384615384\n"
     ]
    }
   ],
   "source": [
    "count = d_model['outcome'].value_counts()\n",
    "ratio_PastEx_to_Present_Ex = count[1]/count[0]\n",
    "print(f\"Ratio of PastEx to PresentEx: {ratio_PastEx_to_Present_Ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148eaf34-fb7b-41cc-9404-cc2109c2c781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5500815015304399\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit  # this is the inverse logit\n",
    "print(expit(0.201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35191810-e051-4a22-885c-2cda11c65961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
